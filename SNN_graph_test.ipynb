{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather loader init\n",
      "WeatherDataLoader done\n",
      "weather loader exists\n",
      "SpatioTemporalDataset init\n",
      "SpatioTemporalDataset exists\n",
      "StaticGraphLoader init\n",
      "StaticGraphLoader exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tsl.nn.layers import NodeEmbedding, DenseGraphConvOrderK, DiffConv, Norm\n",
    "from tsl.nn.blocks.decoders import MLPDecoder\n",
    "from tsl.nn.blocks.encoders.mlp import MLP\n",
    "from einops.layers.torch import Rearrange\n",
    "from snntorch import utils\n",
    "from models.layers.SynapticChain import SynapticChain\n",
    "from models.layers.LearnableWeight import LearnableWeight\n",
    "\n",
    "from load_data import get_data\n",
    "from DataLoader import WeatherDL\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = get_data()\n",
    "min_max = pickle.load(open('./min_max_test.pkl', 'rb'))\n",
    "temporal_resolution = 6\n",
    "window = 20\n",
    "train = WeatherDL(\n",
    "    data,\n",
    "    time=slice('1978', '1980'),\n",
    "    temporal_resolution=temporal_resolution,\n",
    "    window=window,\n",
    "    min=min_max['min'],\n",
    "    max=min_max['max'],\n",
    "    batch_size=1,\n",
    "    num_workers=6,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    shuffle=False,\n",
    "    normalization_range={'min': 0, 'max': 1}\n",
    "    # multiprocessing_context='fork'\n",
    "    )\n",
    "# min, max = train.data_wrapper.getMinMaxValues()\n",
    "# valid = WeatherDL(\n",
    "#     data,\n",
    "#     time='2003',\n",
    "#     temporal_resolution=temporal_resolution,\n",
    "#     min=min_max['min'],\n",
    "#     max=min_max['max'],\n",
    "#     batch_size=5,\n",
    "#     num_workers=6,\n",
    "#     persistent_workers=True,\n",
    "#     prefetch_factor=2,\n",
    "#     # multiprocessing_context='fork'\n",
    "#     )\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.weighted_rmse2 import WeightedRMSE\n",
    "from metrics.metric_utils import WeatherVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticBatch(\n",
       "  input=(x=[b=1, t=20, n=2048, f=26], edge_index=[2, e=19328], edge_weight=[e=19328]),\n",
       "  target=(y=[b=1, t=40, n=2048, f=26]),\n",
       "  has_mask=False\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = train.spatio_temporal_dataset.n_channels   # n channel\n",
    "n_nodes = train.spatio_temporal_dataset.n_nodes         # n nodes\n",
    "horizon = train.spatio_temporal_dataset.horizon         # n prediction time steps\n",
    "hidden_size = 256\n",
    "learnable_size = 32\n",
    "batch = next(iter(train.data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2591)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rmse = WeightedRMSE(\n",
    "    train.data_wrapper.node_weights,\n",
    "    variables=[\n",
    "        # WeatherVariable('z', 500),\n",
    "        WeatherVariable('t', 850)\n",
    "        ],\n",
    "    min_max=min_max,\n",
    "    denormalize=True\n",
    "    ).to(batch.target.y.device)\n",
    "rmse(batch.input.x[:, -1:], batch.target.y[:, 11:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4877)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = WeightedRMSE(\n",
    "    train.data_wrapper.node_weights,\n",
    "    variables=[\n",
    "        # WeatherVariable('z', 500),\n",
    "        WeatherVariable('t', 850)\n",
    "        ],\n",
    "    min_max=min_max,\n",
    "    denormalize=True,\n",
    "    normalization_range={'min': 0, 'max':1}\n",
    "    ).to(batch.target.y.device)\n",
    "rmse(batch.target.y[:, 0:1], batch.target.y[:, 12:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "node_embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "learnable = LearnableWeight(n_nodes=n_nodes, learnable_weight_dim=learnable_size)\n",
    "new_hidden_size1 = hidden_size+learnable_size\n",
    "space = DiffConv(in_channels=new_hidden_size1, out_channels=new_hidden_size1, k=2)\n",
    "\n",
    "learnable2 = LearnableWeight(n_nodes=n_nodes, learnable_weight_dim=learnable_size)\n",
    "new_hidden_size2 = new_hidden_size1 + learnable_size\n",
    "space2 = DiffConv(in_channels=new_hidden_size2, out_channels=new_hidden_size2, k=2)\n",
    "\n",
    "time_nn = SynapticChain(hidden_size=new_hidden_size2+new_hidden_size1, n_layers=5, output_type='membrane_potential', return_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoder(batch.input.x) + node_embeddings()\n",
    "x = learnable(x)\n",
    "x = space(x, train.spatio_temporal_dataset.edge_index, train.spatio_temporal_dataset.edge_weight)\n",
    "\n",
    "x2 = learnable2(x)\n",
    "x2 = space2(x2, train.spatio_temporal_dataset.edge_index, train.spatio_temporal_dataset.edge_weight)\n",
    "stacked = torch.cat([x2, x], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = time_nn(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 320)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hidden_size1, new_hidden_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 112, 2048, 608]), torch.Size([1, 2048, 608]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.size(), res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from tsl.nn.layers import NodeEmbedding, DenseGraphConvOrderK, DiffConv, Norm\n",
    "from tsl.nn.blocks.decoders import MLPDecoder\n",
    "from tsl.nn.blocks.encoders.mlp import MLP\n",
    "from einops.layers.torch import Rearrange\n",
    "from snntorch import utils\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from models.layers.SynapticChain import SynapticChain\n",
    "from models.layers.LearnableWeight import LearnableWeight\n",
    "from models.layers.MultiParam import MultiParam\n",
    "\n",
    "class SkipConnection(nn.Module):\n",
    "    def forward(self, x, out):\n",
    "        return x + out[:, -x.size(1):]\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def forward(self, x, out):\n",
    "        return x + out\n",
    "\n",
    "        \n",
    "\n",
    "class TSNStacked(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 ff_size: int = 256,\n",
    "                 gnn_kernel: int = 2,\n",
    "                 output_type: Literal[\"spike\", \"synaptic_current\", \"membrane_potential\"] = \"spike\",\n",
    "                 learnable_feature_size = 64,\n",
    "                 number_of_blocks = 2,\n",
    "                 number_of_temporal_steps = 3,\n",
    "                 dropout: float = 0.3,\n",
    "                 ) -> None:\n",
    "        super(TSNStacked, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.output_type = output_type\n",
    "        \n",
    "        self.encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        assert n_nodes is not None\n",
    "        self.source_embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "        self.target_embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "        \n",
    "\n",
    "        temporal = []\n",
    "        spatial = []\n",
    "        dense_sconvs = []\n",
    "        skip_connections = []\n",
    "        learnable_weights = []\n",
    "        norms = []\n",
    "        new_hidden_size = 0\n",
    "        for i in range(number_of_blocks):\n",
    "            # is_last = i == number_of_blocks - 1\n",
    "            learnable = LearnableWeight(n_nodes=n_nodes, learnable_weight_dim=learnable_feature_size)\n",
    "            # new_hidden_size = hidden_size + ((i + 1) * learnable_feature_size) \n",
    "            hidden_size = hidden_size + learnable_feature_size\n",
    "            # time_nn = SynapticChain(\n",
    "            #     hidden_size=new_hidden_size,\n",
    "            #     return_last=is_last,\n",
    "            #     output_type=output_type,\n",
    "            #     n_layers=number_of_temporal_steps,\n",
    "            #     )\n",
    "            # space_nn = DiffConv(\n",
    "            #                 # in_channels=hidden_size * ((3-1)**2),\n",
    "            #                 in_channels=hidden_size,\n",
    "            #                 out_channels=hidden_size,\n",
    "            #                 k=gnn_kernel)\n",
    "            dense_sconvs.append(\n",
    "                    DenseGraphConvOrderK(input_size=hidden_size,\n",
    "                                         output_size=hidden_size,\n",
    "                                         support_len=1,\n",
    "                                         order=3, # spatial kernel size\n",
    "                                         include_self=False,\n",
    "                                         channel_last=True))\n",
    "            learnable_weights.append(learnable)\n",
    "            # skip_connections.append(nn.Linear(hidden_size, ff_size))\n",
    "            # temporal.append(time_nn)\n",
    "            # spatial.append(space_nn)\n",
    "            norms.append(Norm('batch', hidden_size))\n",
    "            new_hidden_size += hidden_size\n",
    "        \n",
    "        self.learnable = nn.ModuleList(learnable_weights)\n",
    "        self.temporal = nn.ModuleList(temporal)\n",
    "        # self.spatial = nn.ModuleList(spatial)\n",
    "        self.dense_sconvs = nn.ModuleList(dense_sconvs)\n",
    "        # self.skip_connections = nn.ModuleList(skip_connections)\n",
    "        self.norms = nn.ModuleList(norms)\n",
    "        self.time_nn = SynapticChain(hidden_size=new_hidden_size, n_layers=number_of_temporal_steps, output_type=output_type, return_last=True)\n",
    "        # _____________________________________________________________________\n",
    "        \n",
    "        # self.decoder = nn.Linear(hidden_size, input_size * horizon)\n",
    "        # self.rearrange = Rearrange('b n (t f) -> b t n f', t=horizon)\n",
    "\n",
    "        self.readout = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            MLPDecoder(input_size=new_hidden_size,\n",
    "                       hidden_size=2 * new_hidden_size,\n",
    "                       output_size=input_size,\n",
    "                       horizon=horizon,\n",
    "                       activation='relu'))\n",
    "\n",
    "    def get_learned_adj(self):\n",
    "        logits = F.relu(self.source_embeddings() @ self.target_embeddings().T)\n",
    "        adj = torch.softmax(logits, dim=1)\n",
    "        return adj\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        assert not torch.isnan(x).any()\n",
    "        # x: [batch time nodes features]\n",
    "        # utils.reset(self.temporal)\n",
    "        # x_enc = self.encoder(x)  # linear encoder: x_enc = xΘ + b\n",
    "        # x_emb = x_enc + self.node_embeddings()  # add node-identifier embeddings\n",
    "        # out = torch.zeros(1, x.size(1), 1, 1, device=x.device)\n",
    "    \n",
    "        x = self.encoder(x) + self.node_embeddings()\n",
    "        adj_z = self.get_learned_adj()\n",
    "        # for p1, p2, p3, p4 in zip(self.phase1, self.phase2, self.phase3, self.phase4):\n",
    "        #     resid = x\n",
    "        #     utils.reset(p1)\n",
    "        #     x = checkpoint(p1, x, use_reentrant=False)\n",
    "        #     res = checkpoint(p2, [x, out], use_reentrant=False)\n",
    "        #     out = res[0]\n",
    "        #     print(x.size())\n",
    "        #     res = checkpoint(p3, [x, edge_index, edge_weight, adj_z], use_reentrant=False)\n",
    "        #     x = res[0]\n",
    "        #     res = checkpoint(p4, [x, resid], use_reentrant=False)\n",
    "        #     x = res[0]\n",
    "        # learned_edge_index = adj_z.nonzero().t().contiguous()\n",
    "        # ----------------------------------------------------------------------\n",
    "        processed = []\n",
    "        for i, (add_features, space, norm) in enumerate(zip(\n",
    "            self.learnable,\n",
    "            # self.spatial,\n",
    "            self.dense_sconvs,\n",
    "            self.norms,\n",
    "            )):\n",
    "            # utils.reset(time)\n",
    "            x = checkpoint(add_features, x)\n",
    "            # x = add_features(x)\n",
    "            # x = space(x, adj_z)\n",
    "            x = checkpoint(space, x, adj_z)\n",
    "            # x = norm(x)\n",
    "            x = checkpoint(norm, x)\n",
    "            processed.append(x)\n",
    "            \n",
    "            # res = x\n",
    "            \n",
    "            # x = checkpoint(time, x)\n",
    "            # x = time(x)\n",
    "            # assert not torch.isnan(x).any()\n",
    "            # # out = checkpoint(skip_conn, x) + out[:, -x.size(1):]\n",
    "            # out = skip_conn(x) + out[:, -x.size(1):]\n",
    "            # # xs = checkpoint(space, x, self.edge_index, self.edge_weight)\n",
    "            # xs = space(x, self.edge_index, self.edge_weight)\n",
    "            # # xs = space(x, learned_edge_index)\n",
    "            # if len(self.dense_sconvs):\n",
    "            #     # x = xs + checkpoint(self.dense_sconvs[i], x, adj_z)\n",
    "            #     x = xs + self.dense_sconvs[i](x, adj_z)\n",
    "            # # residual connection -> next layer\n",
    "            # x = x + res[:, -x.size(1):]\n",
    "            # x = norm(x)\n",
    "        # ----------------------------------------------------------------------\n",
    "        out = checkpoint(self.time_nn, torch.cat(processed, dim=-1))\n",
    "            \n",
    "        # return self.readout(out)\n",
    "        return checkpoint(self.readout, out)\n",
    "            \n",
    "        # x_out = self.decoder(x_emb)  # linear decoder: z=[b n f] -> x_out=[b n t⋅f]\n",
    "        # x_horizon = self.rearrange(x_out)\n",
    "        # return x_horizon\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TSNStacked(\n",
    "    input_size=input_size,\n",
    "    n_nodes=n_nodes,\n",
    "    horizon=horizon,\n",
    "    output_type='membrane_potential',\n",
    "    learnable_feature_size=32,\n",
    "    number_of_blocks=2,\n",
    "    number_of_temporal_steps=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSNStacked(\n",
       "  (encoder): Linear(in_features=65, out_features=256, bias=True)\n",
       "  (node_embeddings): NodeEmbedding(n_nodes=2048, embedding_size=256)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (source_embeddings): NodeEmbedding(n_nodes=2048, embedding_size=256)\n",
       "  (target_embeddings): NodeEmbedding(n_nodes=2048, embedding_size=256)\n",
       "  (learnable): ModuleList(\n",
       "    (0-1): 2 x LearnableWeight()\n",
       "  )\n",
       "  (temporal): ModuleList()\n",
       "  (dense_sconvs): ModuleList(\n",
       "    (0): DenseGraphConvOrderK(\n",
       "      (mlp): Conv2d(864, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): DenseGraphConvOrderK(\n",
       "      (mlp): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): Norm(batch, 288)\n",
       "    (1): Norm(batch, 320)\n",
       "  )\n",
       "  (time_nn): SynapticChain(\n",
       "    (chain): Sequential(\n",
       "      (0): Synaptic()\n",
       "      (1): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (2): Synaptic()\n",
       "      (3): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (4): Synaptic()\n",
       "      (5): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (6): Synaptic()\n",
       "      (7): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (8): Synaptic()\n",
       "      (9): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (10): Synaptic()\n",
       "      (11): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (12): Synaptic()\n",
       "      (13): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (14): Synaptic()\n",
       "      (15): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (16): Synaptic()\n",
       "      (17): Linear(in_features=608, out_features=608, bias=True)\n",
       "      (18): Synaptic()\n",
       "      (19): Linear(in_features=608, out_features=608, bias=True)\n",
       "    )\n",
       "    (synaptic_out): Synaptic()\n",
       "    (linear_out): Linear(in_features=608, out_features=608, bias=True)\n",
       "    (readout): MLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Dense(\n",
       "          (affinity): Linear(in_features=608, out_features=1216, bias=True)\n",
       "          (activation): PReLU(num_parameters=1)\n",
       "          (dropout): Identity()\n",
       "        )\n",
       "      )\n",
       "      (readout): Linear(in_features=1216, out_features=608, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (readout): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): MLPDecoder(\n",
       "      (readout): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Dense(\n",
       "            (affinity): Linear(in_features=608, out_features=1216, bias=True)\n",
       "            (activation): ReLU()\n",
       "            (dropout): Identity()\n",
       "          )\n",
       "        )\n",
       "        (readout): Linear(in_features=1216, out_features=2600, bias=True)\n",
       "      )\n",
       "      (rearrange): Rearrange('b n (h f) -> b h n f', f=65, h=40)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = m(*batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 2048, 65])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": "Shape mismatch, 1 != 2048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m rmse \u001b[38;5;241m=\u001b[39m WeightedRMSE(\n\u001b[1;32m      2\u001b[0m     train\u001b[38;5;241m.\u001b[39mdata_wrapper\u001b[38;5;241m.\u001b[39mnode_weights,\n\u001b[1;32m      3\u001b[0m     variables\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     denormalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(batch\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torchmetrics/metric.py:296\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TorchMetricsUserError(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Metric shouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be synced when performing ``forward``. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHINT: Did you forget to call ``unsync`` ?.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_state_update \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_state_update \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_sync_on_step:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_full_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torchmetrics/metric.py:311\u001b[0m, in \u001b[0;36mMetric._forward_full_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward computation using two calls to `update`.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03mDoing this secures that metrics that need access to the full metric state during `update` works as expected.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# global accumulation\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m _update_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_sync_on_step\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torchmetrics/metric.py:467\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[1;32m    460\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torchmetrics/metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/tsl/metrics/torch/metric_base.py:117\u001b[0m, in \u001b[0;36mMaskedMetric.update\u001b[0;34m(self, y_hat, y, mask)\u001b[0m\n\u001b[1;32m    115\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mat]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_masked(mask):\n\u001b[0;32m--> 117\u001b[0m     val, numel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_masked\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     val, numel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_std(y_hat, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/tsl/metrics/torch/metric_base.py:98\u001b[0m, in \u001b[0;36mMaskedMetric._compute_masked\u001b[0;34m(self, y_hat, y, mask)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_masked\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_hat, y, mask):\n\u001b[1;32m     97\u001b[0m     _check_same_shape(y_hat, y)\n\u001b[0;32m---> 98\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_mask(mask, val)\n\u001b[1;32m    100\u001b[0m     val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(mask, val, torch\u001b[38;5;241m.\u001b[39mzeros_like(val))\n",
      "File \u001b[0;32m~/Desktop/weather/metrics/weighted_rmse2.py:53\u001b[0m, in \u001b[0;36m_WeightedRMSE.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/weather/metrics/weighted_rmse2.py:41\u001b[0m, in \u001b[0;36m_WeightedRMSE.forward\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m     38\u001b[0m predictions, ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_original_shape(predictions), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_original_shape(ground_truth)\n\u001b[1;32m     40\u001b[0m diff \u001b[38;5;241m=\u001b[39m (predictions[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables] \u001b[38;5;241m-\u001b[39m ground_truth[:, :,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables])\n\u001b[0;32m---> 41\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrefine_names(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _spatial_average_l2_norm(diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mrefine_names(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/einops/layers/torch.py:15\u001b[0m, in \u001b[0;36mRearrange.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     14\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multirecipe[\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim]\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_for_scriptable_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axes_lengths\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/einops/_torch_specific.py:87\u001b[0m, in \u001b[0;36mapply_for_scriptable_torch\u001b[0;34m(recipe, tensor, reduction_type, axes_dims)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_for_scriptable_torch\u001b[39m(\n\u001b[1;32m     77\u001b[0m     recipe: TransformRecipe, tensor: torch\u001b[38;5;241m.\u001b[39mTensor, reduction_type: \u001b[38;5;28mstr\u001b[39m, axes_dims: List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]\n\u001b[1;32m     78\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     79\u001b[0m     backend \u001b[38;5;241m=\u001b[39m TorchJitBackend\n\u001b[1;32m     80\u001b[0m     (\n\u001b[1;32m     81\u001b[0m         init_shapes,\n\u001b[1;32m     82\u001b[0m         axes_reordering,\n\u001b[1;32m     83\u001b[0m         reduced_axes,\n\u001b[1;32m     84\u001b[0m         added_axes,\n\u001b[1;32m     85\u001b[0m         final_shapes,\n\u001b[1;32m     86\u001b[0m         n_axes_w_added,\n\u001b[0;32m---> 87\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct_from_shape_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m init_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/einops/einops.py:183\u001b[0m, in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[0;34m(self, shape, axes_dims)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unknown_axes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(length, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(known_product, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m length \u001b[38;5;241m!=\u001b[39m known_product:\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlength\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mknown_product\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# assert len(unknown_axes) == 1, 'this is enforced when recipe is created, so commented out'\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(length, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(known_product, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m length \u001b[38;5;241m%\u001b[39m known_product \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mEinopsError\u001b[0m: Shape mismatch, 1 != 2048"
     ]
    }
   ],
   "source": [
    "rmse = WeightedRMSE(\n",
    "    train.data_wrapper.node_weights,\n",
    "    variables=[\n",
    "        # WeatherVariable('z', 500),\n",
    "        WeatherVariable('t', 850)\n",
    "        ],\n",
    "    min_max=min_max,\n",
    "    denormalize=True\n",
    "    ).to(batch.target.y.device)\n",
    "rmse(batch.target.y[:, 0:1], batch.target.y[:, 23:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SynapticAttention import SynapticAttention\n",
    "model = SynapticAttention(input_size=input_size, n_nodes=n_nodes, hidden_size=hidden_size, horizon=horizon)\n",
    "model.to(device)\n",
    "batch.to(device)\n",
    "res = model(*batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4408.3960, device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = rmse.to(res.device)\n",
    "rmse(batch.input.x[:, -40:], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv, GATConv\n",
    "from einops import rearrange\n",
    "import snntorch as snn\n",
    "from snntorch import functional as SF\n",
    "encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "\n",
    "encoded = encoder(batch.input.x)\n",
    "emb = encoded + embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(1, emb.size(1), 1, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = GATConv(in_channels=hidden_size, out_channels=32)(emb[:, 0, :, :], batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, t, n, f = emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb[:, 0, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional, Tuple, Union\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import Tensor\n",
    "# from torch.nn import Parameter\n",
    "# from torch_geometric.nn.conv import MessagePassing\n",
    "# from torch_geometric.nn.dense.linear import Linear\n",
    "# from torch_geometric.nn.inits import glorot, zeros\n",
    "# from torch_geometric.typing import Adj, OptPairTensor, OptTensor\n",
    "# from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "# from torch_sparse import SparseTensor, set_diag\n",
    "\n",
    "# from tsl.nn.functional import sparse_softmax\n",
    "\n",
    "# import snntorch as snn\n",
    "\n",
    "\n",
    "# class GSATConv(MessagePassing):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels: Union[int, Tuple[int, int]],\n",
    "#         out_channels: int,\n",
    "#         heads: int = 1,\n",
    "#         concat: bool = True,\n",
    "#         dim: int = -2,\n",
    "#         negative_slope: float = 0.2,\n",
    "#         dropout: float = 0.0,\n",
    "#         add_self_loops: bool = True,\n",
    "#         edge_dim: Optional[int] = None,\n",
    "#         fill_value: Union[float, Tensor, str] = 'mean',\n",
    "#         bias: bool = True,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         kwargs.setdefault('aggr', 'add')\n",
    "#         super().__init__(node_dim=dim, **kwargs)\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.heads = heads\n",
    "#         self.concat = concat\n",
    "#         self.negative_slope = negative_slope\n",
    "#         self.dropout = dropout\n",
    "#         self.add_self_loops = add_self_loops\n",
    "#         self.edge_dim = edge_dim\n",
    "#         self.fill_value = fill_value\n",
    "\n",
    "#         if self.concat:\n",
    "#             self.head_channels = self.out_channels // self.heads\n",
    "#             assert self.head_channels * self.heads == self.out_channels, \\\n",
    "#                 \"`out_channels` must be divisible by `heads`.\"\n",
    "#         else:\n",
    "#             self.head_channels = self.out_channels\n",
    "\n",
    "#         # In case we are operating in bipartite graphs, we apply separate\n",
    "#         # transformations 'lin_src' and 'lin_dst' to source and target nodes:\n",
    "#         # if isinstance(in_channels, int):\n",
    "#         self.lin_src = snn.Synaptic(\n",
    "#             alpha=0.9,\n",
    "#             beta=0.8,\n",
    "#             learn_alpha=True,\n",
    "#             learn_beta=True,\n",
    "#             learn_threshold=True,\n",
    "#             # init_hidden=True,\n",
    "#             # output=True\n",
    "#         )\n",
    "#         # Linear(in_channels,\n",
    "#         #                         heads * self.head_channels,\n",
    "#         #                         bias=False,\n",
    "#         #                         weight_initializer='glorot')\n",
    "#         self.lin_dst = self.lin_src\n",
    "#         # else:\n",
    "#         #     self.lin_src = Linear(in_channels[0],\n",
    "#         #                           heads * self.head_channels,\n",
    "#         #                           False,\n",
    "#         #                           weight_initializer='glorot')\n",
    "#         #     self.lin_dst = Linear(in_channels[1],\n",
    "#         #                           heads * self.head_channels,\n",
    "#         #                           False,\n",
    "#         #                           weight_initializer='glorot')\n",
    "\n",
    "#         # The learnable parameters to compute attention coefficients:\n",
    "#         self.att_src = Parameter(torch.Tensor(1, heads, self.head_channels))\n",
    "#         self.att_dst = Parameter(torch.Tensor(1, heads, self.head_channels))\n",
    "\n",
    "#         if edge_dim is not None:\n",
    "#             self.edge_synaptic = snn.Synaptic(\n",
    "#                 alpha=0.9,\n",
    "#                 beta=0.8,\n",
    "#                 learn_alpha=True,\n",
    "#                 learn_beta=True,\n",
    "#                 learn_threshold=True,\n",
    "#                 # init_hidden=True,\n",
    "#                 # output=True,\n",
    "#             )\n",
    "#             self.lin_edge = Linear(edge_dim,\n",
    "#                                    heads * self.head_channels,\n",
    "#                                    bias=False,\n",
    "#                                    weight_initializer='glorot')\n",
    "#             self.att_edge = Parameter(\n",
    "#                 torch.Tensor(1, heads, self.head_channels))\n",
    "#         else:\n",
    "#             self.lin_edge = None\n",
    "#             self.register_parameter('att_edge', None)\n",
    "\n",
    "#         if bias and concat:\n",
    "#             self.bias = Parameter(torch.Tensor(heads * self.head_channels))\n",
    "#         elif bias and not concat:\n",
    "#             self.bias = Parameter(torch.Tensor(out_channels))\n",
    "#         else:\n",
    "#             self.register_parameter('bias', None)\n",
    "\n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         # self.lin_src.reset_parameters()\n",
    "#         # self.lin_dst.reset_parameters()\n",
    "#         if self.lin_edge is not None:\n",
    "#             self.lin_edge.reset_parameters()\n",
    "#         glorot(self.att_src)\n",
    "#         glorot(self.att_dst)\n",
    "#         glorot(self.att_edge)\n",
    "#         zeros(self.bias)\n",
    "\n",
    "#     def forward(self,\n",
    "#                 x: Union[Tensor, OptPairTensor],\n",
    "#                 edge_index: Adj,\n",
    "#                 edge_attr: OptTensor = None,\n",
    "#                 need_weights: bool = False):\n",
    "#         \"\"\"\"\"\"\n",
    "#         node_dim = self.node_dim\n",
    "#         self.node_dim = (node_dim + x.dim()) if node_dim < 0 else node_dim\n",
    "#         b, t, n, c = x.size()\n",
    "\n",
    "#         N, H, C = n, self.heads, self.head_channels\n",
    "\n",
    "#         syn, mem = self.lin_src.init_synaptic()\n",
    "#         if self.edge_synaptic is not None:\n",
    "#             syn_e, membrane_e = self.edge_synaptic.init_synaptic()\n",
    "#         # syn, membrane_pot = synaptic.init_synaptic()\n",
    "#         # We first transform the input node features. If a tuple is passed, we\n",
    "#         # transform source and target node features via separate weights:\n",
    "#         # if isinstance(x, Tensor):\n",
    "#         # print(\"x size\", x.size())\n",
    "#         for timestep in range(t):\n",
    "#             data_at_time = x[:, timestep, : , :]\n",
    "#             spike, syn, mem = self.lin_src(data_at_time, syn, mem)\n",
    "#             x_src = x_dst = mem.view(*data_at_time.shape[:-1], H, C)\n",
    "#             # else:  # Tuple of source and target node features:\n",
    "#             #     x_src, x_dst = x\n",
    "#             #     x_src = self.lin_src(x_src).view(*x_src.shape[:-1], H, C)\n",
    "#             #     if x_dst is not None:\n",
    "#             #         x_dst = self.lin_dst(x_dst).view(*x_dst.shape[:-1], H, C)\n",
    "\n",
    "#             x_node_features = (x_src, x_dst)\n",
    "\n",
    "#             # Next, we compute node-level attention coefficients, both for source\n",
    "#             # and target nodes (if present):\n",
    "#             alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "#             alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
    "#             alpha = (alpha_src, alpha_dst)\n",
    "\n",
    "#             if self.add_self_loops:\n",
    "#                 if isinstance(edge_index, Tensor):\n",
    "#                     edge_index, edge_attr = remove_self_loops(\n",
    "#                         edge_index, edge_attr)\n",
    "#                     edge_index, edge_attr = add_self_loops(\n",
    "#                         edge_index,\n",
    "#                         edge_attr,\n",
    "#                         fill_value=self.fill_value,\n",
    "#                         num_nodes=N)\n",
    "#                 elif isinstance(edge_index, SparseTensor):\n",
    "#                     if self.edge_dim is None:\n",
    "#                         edge_index = set_diag(edge_index)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError(\n",
    "#                             \"The usage of 'edge_attr' and 'add_self_loops' \"\n",
    "#                             \"simultaneously is currently not yet supported for \"\n",
    "#                             \"'edge_index' in a 'SparseTensor' form\")\n",
    "\n",
    "#             # edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\n",
    "#             alpha, syn_e, membrane_e = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr, syn_e=syn_e, membrane_e=membrane_e)\n",
    "\n",
    "#             # propagate_type: (x: OptPairTensor, alpha: Tensor)\n",
    "#             out = self.propagate(edge_index, x=x_node_features, alpha=alpha, size=(N, N))\n",
    "\n",
    "#             if self.concat:\n",
    "#                 out = out.view(*out.shape[:-2], self.out_channels)\n",
    "#             else:\n",
    "#                 out = out.mean(dim=-2)\n",
    "\n",
    "#             if self.bias is not None:\n",
    "#                 out += self.bias\n",
    "\n",
    "#             if need_weights:\n",
    "#                 # alpha rearrange: [... e ... h] -> [e ... h]\n",
    "#                 alpha = torch.movedim(alpha, self.node_dim, 0)\n",
    "#                 if isinstance(edge_index, Tensor):\n",
    "#                     alpha = (edge_index, alpha)\n",
    "#                 elif isinstance(edge_index, SparseTensor):\n",
    "#                     alpha = edge_index.set_value(alpha, layout='coo')\n",
    "#             else:\n",
    "#                 alpha = None\n",
    "\n",
    "#             self.node_dim = node_dim\n",
    "\n",
    "#         return out, alpha\n",
    "\n",
    "#     def edge_update(self, alpha_j: Tensor, alpha_i: OptTensor,\n",
    "#                     edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "#                     size_i: Optional[int], membrane_e=None, syn_e=None) -> Tensor:\n",
    "#         \"\"\"\"\"\"\n",
    "#         # Given edge-level attention coefficients for source and target nodes,\n",
    "#         # we simply need to sum them up to \"emulate\" concatenation:\n",
    "#         alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "#         if edge_attr is not None:\n",
    "#             if edge_attr.dim() == 1:\n",
    "#                 edge_attr = edge_attr.view(-1, 1)\n",
    "#             assert self.lin_edge is not None\n",
    "#             # edge_attr = self.lin_edge(edge_attr)\n",
    "#             spike, syn, mem = self.edge_synaptic(edge_attr, syn_e, membrane_e)\n",
    "#             edge_attr = self.lin_edge(mem)\n",
    "#             edge_attr = edge_attr.view(-1, self.heads, self.head_channels)\n",
    "#             alpha_edge = (edge_attr * self.att_edge).sum(dim=-1)\n",
    "#             shape = [1] * (alpha.ndim - 1) + [self.heads]\n",
    "#             shape[self.node_dim] = alpha_edge.size(0)\n",
    "#             alpha = alpha + alpha_edge.view(shape)\n",
    "\n",
    "#         alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "#         alpha = sparse_softmax(alpha,\n",
    "#                                index,\n",
    "#                                num_nodes=size_i,\n",
    "#                                ptr=ptr,\n",
    "#                                dim=self.node_dim)\n",
    "#         alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "#         return alpha, syn, mem\n",
    "\n",
    "#     def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n",
    "#         \"\"\"\"\"\"\n",
    "#         return alpha.unsqueeze(-1) * x_j\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "#                 f'{self.out_channels}, heads={self.heads})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = DiffConv(hidden_size, out_channels=hidden_size, k=2, activation='relu')\n",
    "emn_s = spatial(emb, batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.cat((emb, emn_s), dim=-1)\n",
    "stacked.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.layers.GSATConv import GSATConv\n",
    "res = GSATConv(in_channels=(1 * hidden_size) + hidden_size, out_channels=hidden_size, dim = 1, edge_dim=1)(stacked, batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter(torch.Tensor(1, 4, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.9\n",
    "rlif = snn.RLeaky(beta=beta, linear_features=hidden_size)\n",
    "spike, membrane_pot = rlif.init_rleaky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import surrogate\n",
    "spike_grad=surrogate.atan(alpha=2.0)\n",
    "thresh=1\n",
    "l = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=thresh, output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiplier(i):\n",
    "    return max((i * 2), 1)\n",
    "    # return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"size {emb.size(-1) * get_multiplier(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)\n",
    "# beta = torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)\n",
    "synaptic = snn.Synaptic(\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True\n",
    "    )\n",
    "# syn, membrane_pot = synaptic.init_synaptic()\n",
    "\n",
    "synaptic2 = snn.Synaptic(\n",
    "    # alpha=torch.Tensor(emb.size(-1) * 2),\n",
    "    # beta=torch.Tensor(emb.size(-1) * 2),\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True\n",
    "    )\n",
    "# syn2, membrane_pot2 = synaptic2.init_synaptic()\n",
    "\n",
    "synaptic3 = snn.Synaptic(\n",
    "    # alpha=torch.Tensor(emb.size(-1) * 3),\n",
    "    # beta=torch.Tensor(emb.size(-1) * 3),\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True,\n",
    "    output=True\n",
    "    )\n",
    "# syn3, membrane_pot3 = synaptic3.init_synaptic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synaptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=emb.size(-1), out_features=emb.size(-1))\n",
    "# linear2 = torch.nn.Linear(in_features=emb.size(-1) * 2, out_features=emb.size(-1) * 2)\n",
    "linear2 = torch.nn.Linear(in_features=emb.size(-1), out_features=emb.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.layers.SynapticChain import SynapticChain\n",
    "chain = SynapticChain(hidden_size=hidden_size, return_last=True)\n",
    "spike, mem_pot, syn_cur = chain(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(syn_cur).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes =[]\n",
    "mem_pots = []\n",
    "# flat = emb.flatten(start_dim=2)\n",
    "for timestep in range(t):\n",
    "    # spike, syn, membrane_pot = synaptic(emb[:, timestep,:, :], syn, membrane_pot)\n",
    "    spike = synaptic(emb[:, timestep,:, :])\n",
    "    l = linear(spike)\n",
    "    # spike2, syn2, membrane_pot2 = synaptic2(torch.cat((spike, emb[:, timestep,:, :]), dim=2), syn2, membrane_pot2)\n",
    "    # spike2, syn2, membrane_pot2 = synaptic2(torch.cat((l, emb[:, timestep,:, :]), dim=2), syn2, membrane_pot2)\n",
    "    spike2 = synaptic2(l)\n",
    "    l2 = linear2(spike2)\n",
    "    \n",
    "    # spike3, syn3, membrane_pot3 = synaptic3(torch.cat((l2, l), dim=2), syn3, membrane_pot3)\n",
    "    spike3, syn3, membrane_pot3 = synaptic3(l2)\n",
    "    \n",
    "    # spike, syn, membrane_pot = rsynaptic(flat[:, timestep, :], spike, syn, membrane_pot)\n",
    "    # spike, syn, membrane_pot = rsynaptic(emb[:, timestep, :, :], spike, syn, membrane_pot)\n",
    "    # spike, syn, membrane_pot = rsynaptic_conv(emb[:, timestep, :, :], spike, syn, membrane_pot)\n",
    "    spikes.append(spike3)\n",
    "    mem_pots.append(membrane_pot3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "855900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((spike, emb[:, 0,:, :]), dim=2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike.size(), syn.size(), membrane_pot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = DiffConv(in_channels=hidden_size,\n",
    "                                 out_channels=hidden_size,\n",
    "                                 k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_spikes = torch.stack(spikes, 1)\n",
    "post_space = space(stacked_spikes[:,-1,:,:], batch.edge_index, batch.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.Linear(32, input_size * horizon)\n",
    "post_decoder = decoder(post_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_decoder.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "rearrange = Rearrange('b n (t f) -> b t n f', t=horizon)\n",
    "post_rearange = rearrange(post_decoder)\n",
    "post_rearange.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rearange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(spikes, 1).size(), torch.stack(spikes, 1).reshape((b,t,n,-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike.reshape((b,n,-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=thresh)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb[:, 0, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk, mem = rlif(emb[:, 0, :, :], spike, membrane_pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk.size(), mem.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TemporalSpikeGraphConvNet import TemporalSpikeGraphConvNet\n",
    "from models.TemporalSynapticGraphConvNet import TemporalSynapticGraphConvNet\n",
    "\n",
    "model = TemporalSynapticGraphConvNet(input_size=input_size,\n",
    "                               n_nodes=n_nodes,\n",
    "                               horizon=horizon,\n",
    "                               hidden_size=hidden_size * 5,\n",
    "                               output_type=\"membrane_potential\",\n",
    "                               number_of_blocks=3\n",
    "                               )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "batch.to(device)\n",
    "res = model(*batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
