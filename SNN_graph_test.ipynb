{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "from load_data import get_data\n",
    "from DataLoader import WeatherDL\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = get_data()\n",
    "min_max = pickle.load(open('./min_max_test.pkl', 'rb'))\n",
    "train = WeatherDL(\n",
    "    data,\n",
    "    time=slice('2000', '2002'),\n",
    "    temporal_resolution=3,\n",
    "    # window=84,\n",
    "    min=min_max['min'],\n",
    "    max=min_max['max'],\n",
    "    batch_size=2,\n",
    "    num_workers=6,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    # multiprocessing_context='fork'\n",
    "    )\n",
    "# min, max = train.data_wrapper.getMinMaxValues()\n",
    "valid = WeatherDL(\n",
    "    data,\n",
    "    time='2003',\n",
    "    temporal_resolution=3,\n",
    "    min=min_max['min'],\n",
    "    max=min_max['max'],\n",
    "    batch_size=5,\n",
    "    num_workers=6,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    # multiprocessing_context='fork'\n",
    "    )\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticBatch(\n",
       "  input=(x=[b=3, t=112, n=2048, f=65], edge_index=[2, e=19328], edge_weight=[e=19328]),\n",
       "  target=(y=[b=3, t=40, n=2048, f=65]),\n",
       "  has_mask=False\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = train.spatio_temporal_dataset.n_channels   # n channel\n",
    "n_nodes = train.spatio_temporal_dataset.n_nodes         # n nodes\n",
    "horizon = train.spatio_temporal_dataset.horizon         # n prediction time steps\n",
    "hidden_size = 256\n",
    "batch = next(iter(train.data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip torch.Size([3, 112, 2048, 256]), out torch.Size([1, 112, 1, 1])\n",
      "skip torch.Size([3, 1, 2048, 256]), out torch.Size([3, 112, 2048, 256])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 672.00 MiB. GPU 0 has a total capacty of 23.43 GiB of which 140.38 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 968.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/weather/models/SynapticAttention.py:94\u001b[0m, in \u001b[0;36mSynapticAttention.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     92\u001b[0m     out \u001b[38;5;241m=\u001b[39m skip_processed \u001b[38;5;241m+\u001b[39m out[:, \u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m):]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_sconvs):\n\u001b[0;32m---> 94\u001b[0m         x \u001b[38;5;241m=\u001b[39m processed \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_sconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m res[:, \u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m):]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# z, _ = self.attention(x_enc, edge_index, edge_weight)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# assert not torch.isnan(z).any()\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# z, _ = self.attention2(z, edge_index, edge_weight)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# x_horizon = self.rearrange(x_out)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# return x_horizon\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/weather/lib/python3.11/site-packages/tsl/nn/layers/graph_convs/dense_graph_conv.py:88\u001b[0m, in \u001b[0;36mDenseGraphConvOrderK.forward\u001b[0;34m(self, x, support)\u001b[0m\n\u001b[1;32m     86\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder):\n\u001b[0;32m---> 88\u001b[0m         x1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mncvl, wv -> ncwl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(x1)\n\u001b[1;32m     91\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 672.00 MiB. GPU 0 has a total capacty of 23.43 GiB of which 140.38 MiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 21.46 GiB is allocated by PyTorch, and 968.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from models.SynapticAttention import SynapticAttention\n",
    "model = SynapticAttention(input_size=input_size, n_nodes=n_nodes, hidden_size=hidden_size, horizon=horizon)\n",
    "model.to(device)\n",
    "batch.to(device)\n",
    "res = model(*batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv, GATConv\n",
    "from einops import rearrange\n",
    "import snntorch as snn\n",
    "from snntorch import functional as SF\n",
    "encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "embeddings = NodeEmbedding(n_nodes=n_nodes, emb_size=hidden_size)\n",
    "\n",
    "encoded = encoder(batch.input.x)\n",
    "emb = encoded + embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(1, emb.size(1), 1, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = GATConv(in_channels=hidden_size, out_channels=32)(emb[:, 0, :, :], batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, t, n, f = emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb[:, 0, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional, Tuple, Union\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import Tensor\n",
    "# from torch.nn import Parameter\n",
    "# from torch_geometric.nn.conv import MessagePassing\n",
    "# from torch_geometric.nn.dense.linear import Linear\n",
    "# from torch_geometric.nn.inits import glorot, zeros\n",
    "# from torch_geometric.typing import Adj, OptPairTensor, OptTensor\n",
    "# from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "# from torch_sparse import SparseTensor, set_diag\n",
    "\n",
    "# from tsl.nn.functional import sparse_softmax\n",
    "\n",
    "# import snntorch as snn\n",
    "\n",
    "\n",
    "# class GSATConv(MessagePassing):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels: Union[int, Tuple[int, int]],\n",
    "#         out_channels: int,\n",
    "#         heads: int = 1,\n",
    "#         concat: bool = True,\n",
    "#         dim: int = -2,\n",
    "#         negative_slope: float = 0.2,\n",
    "#         dropout: float = 0.0,\n",
    "#         add_self_loops: bool = True,\n",
    "#         edge_dim: Optional[int] = None,\n",
    "#         fill_value: Union[float, Tensor, str] = 'mean',\n",
    "#         bias: bool = True,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         kwargs.setdefault('aggr', 'add')\n",
    "#         super().__init__(node_dim=dim, **kwargs)\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.heads = heads\n",
    "#         self.concat = concat\n",
    "#         self.negative_slope = negative_slope\n",
    "#         self.dropout = dropout\n",
    "#         self.add_self_loops = add_self_loops\n",
    "#         self.edge_dim = edge_dim\n",
    "#         self.fill_value = fill_value\n",
    "\n",
    "#         if self.concat:\n",
    "#             self.head_channels = self.out_channels // self.heads\n",
    "#             assert self.head_channels * self.heads == self.out_channels, \\\n",
    "#                 \"`out_channels` must be divisible by `heads`.\"\n",
    "#         else:\n",
    "#             self.head_channels = self.out_channels\n",
    "\n",
    "#         # In case we are operating in bipartite graphs, we apply separate\n",
    "#         # transformations 'lin_src' and 'lin_dst' to source and target nodes:\n",
    "#         # if isinstance(in_channels, int):\n",
    "#         self.lin_src = snn.Synaptic(\n",
    "#             alpha=0.9,\n",
    "#             beta=0.8,\n",
    "#             learn_alpha=True,\n",
    "#             learn_beta=True,\n",
    "#             learn_threshold=True,\n",
    "#             # init_hidden=True,\n",
    "#             # output=True\n",
    "#         )\n",
    "#         # Linear(in_channels,\n",
    "#         #                         heads * self.head_channels,\n",
    "#         #                         bias=False,\n",
    "#         #                         weight_initializer='glorot')\n",
    "#         self.lin_dst = self.lin_src\n",
    "#         # else:\n",
    "#         #     self.lin_src = Linear(in_channels[0],\n",
    "#         #                           heads * self.head_channels,\n",
    "#         #                           False,\n",
    "#         #                           weight_initializer='glorot')\n",
    "#         #     self.lin_dst = Linear(in_channels[1],\n",
    "#         #                           heads * self.head_channels,\n",
    "#         #                           False,\n",
    "#         #                           weight_initializer='glorot')\n",
    "\n",
    "#         # The learnable parameters to compute attention coefficients:\n",
    "#         self.att_src = Parameter(torch.Tensor(1, heads, self.head_channels))\n",
    "#         self.att_dst = Parameter(torch.Tensor(1, heads, self.head_channels))\n",
    "\n",
    "#         if edge_dim is not None:\n",
    "#             self.edge_synaptic = snn.Synaptic(\n",
    "#                 alpha=0.9,\n",
    "#                 beta=0.8,\n",
    "#                 learn_alpha=True,\n",
    "#                 learn_beta=True,\n",
    "#                 learn_threshold=True,\n",
    "#                 # init_hidden=True,\n",
    "#                 # output=True,\n",
    "#             )\n",
    "#             self.lin_edge = Linear(edge_dim,\n",
    "#                                    heads * self.head_channels,\n",
    "#                                    bias=False,\n",
    "#                                    weight_initializer='glorot')\n",
    "#             self.att_edge = Parameter(\n",
    "#                 torch.Tensor(1, heads, self.head_channels))\n",
    "#         else:\n",
    "#             self.lin_edge = None\n",
    "#             self.register_parameter('att_edge', None)\n",
    "\n",
    "#         if bias and concat:\n",
    "#             self.bias = Parameter(torch.Tensor(heads * self.head_channels))\n",
    "#         elif bias and not concat:\n",
    "#             self.bias = Parameter(torch.Tensor(out_channels))\n",
    "#         else:\n",
    "#             self.register_parameter('bias', None)\n",
    "\n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         # self.lin_src.reset_parameters()\n",
    "#         # self.lin_dst.reset_parameters()\n",
    "#         if self.lin_edge is not None:\n",
    "#             self.lin_edge.reset_parameters()\n",
    "#         glorot(self.att_src)\n",
    "#         glorot(self.att_dst)\n",
    "#         glorot(self.att_edge)\n",
    "#         zeros(self.bias)\n",
    "\n",
    "#     def forward(self,\n",
    "#                 x: Union[Tensor, OptPairTensor],\n",
    "#                 edge_index: Adj,\n",
    "#                 edge_attr: OptTensor = None,\n",
    "#                 need_weights: bool = False):\n",
    "#         \"\"\"\"\"\"\n",
    "#         node_dim = self.node_dim\n",
    "#         self.node_dim = (node_dim + x.dim()) if node_dim < 0 else node_dim\n",
    "#         b, t, n, c = x.size()\n",
    "\n",
    "#         N, H, C = n, self.heads, self.head_channels\n",
    "\n",
    "#         syn, mem = self.lin_src.init_synaptic()\n",
    "#         if self.edge_synaptic is not None:\n",
    "#             syn_e, membrane_e = self.edge_synaptic.init_synaptic()\n",
    "#         # syn, membrane_pot = synaptic.init_synaptic()\n",
    "#         # We first transform the input node features. If a tuple is passed, we\n",
    "#         # transform source and target node features via separate weights:\n",
    "#         # if isinstance(x, Tensor):\n",
    "#         # print(\"x size\", x.size())\n",
    "#         for timestep in range(t):\n",
    "#             data_at_time = x[:, timestep, : , :]\n",
    "#             spike, syn, mem = self.lin_src(data_at_time, syn, mem)\n",
    "#             x_src = x_dst = mem.view(*data_at_time.shape[:-1], H, C)\n",
    "#             # else:  # Tuple of source and target node features:\n",
    "#             #     x_src, x_dst = x\n",
    "#             #     x_src = self.lin_src(x_src).view(*x_src.shape[:-1], H, C)\n",
    "#             #     if x_dst is not None:\n",
    "#             #         x_dst = self.lin_dst(x_dst).view(*x_dst.shape[:-1], H, C)\n",
    "\n",
    "#             x_node_features = (x_src, x_dst)\n",
    "\n",
    "#             # Next, we compute node-level attention coefficients, both for source\n",
    "#             # and target nodes (if present):\n",
    "#             alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "#             alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
    "#             alpha = (alpha_src, alpha_dst)\n",
    "\n",
    "#             if self.add_self_loops:\n",
    "#                 if isinstance(edge_index, Tensor):\n",
    "#                     edge_index, edge_attr = remove_self_loops(\n",
    "#                         edge_index, edge_attr)\n",
    "#                     edge_index, edge_attr = add_self_loops(\n",
    "#                         edge_index,\n",
    "#                         edge_attr,\n",
    "#                         fill_value=self.fill_value,\n",
    "#                         num_nodes=N)\n",
    "#                 elif isinstance(edge_index, SparseTensor):\n",
    "#                     if self.edge_dim is None:\n",
    "#                         edge_index = set_diag(edge_index)\n",
    "#                     else:\n",
    "#                         raise NotImplementedError(\n",
    "#                             \"The usage of 'edge_attr' and 'add_self_loops' \"\n",
    "#                             \"simultaneously is currently not yet supported for \"\n",
    "#                             \"'edge_index' in a 'SparseTensor' form\")\n",
    "\n",
    "#             # edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\n",
    "#             alpha, syn_e, membrane_e = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr, syn_e=syn_e, membrane_e=membrane_e)\n",
    "\n",
    "#             # propagate_type: (x: OptPairTensor, alpha: Tensor)\n",
    "#             out = self.propagate(edge_index, x=x_node_features, alpha=alpha, size=(N, N))\n",
    "\n",
    "#             if self.concat:\n",
    "#                 out = out.view(*out.shape[:-2], self.out_channels)\n",
    "#             else:\n",
    "#                 out = out.mean(dim=-2)\n",
    "\n",
    "#             if self.bias is not None:\n",
    "#                 out += self.bias\n",
    "\n",
    "#             if need_weights:\n",
    "#                 # alpha rearrange: [... e ... h] -> [e ... h]\n",
    "#                 alpha = torch.movedim(alpha, self.node_dim, 0)\n",
    "#                 if isinstance(edge_index, Tensor):\n",
    "#                     alpha = (edge_index, alpha)\n",
    "#                 elif isinstance(edge_index, SparseTensor):\n",
    "#                     alpha = edge_index.set_value(alpha, layout='coo')\n",
    "#             else:\n",
    "#                 alpha = None\n",
    "\n",
    "#             self.node_dim = node_dim\n",
    "\n",
    "#         return out, alpha\n",
    "\n",
    "#     def edge_update(self, alpha_j: Tensor, alpha_i: OptTensor,\n",
    "#                     edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "#                     size_i: Optional[int], membrane_e=None, syn_e=None) -> Tensor:\n",
    "#         \"\"\"\"\"\"\n",
    "#         # Given edge-level attention coefficients for source and target nodes,\n",
    "#         # we simply need to sum them up to \"emulate\" concatenation:\n",
    "#         alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "#         if edge_attr is not None:\n",
    "#             if edge_attr.dim() == 1:\n",
    "#                 edge_attr = edge_attr.view(-1, 1)\n",
    "#             assert self.lin_edge is not None\n",
    "#             # edge_attr = self.lin_edge(edge_attr)\n",
    "#             spike, syn, mem = self.edge_synaptic(edge_attr, syn_e, membrane_e)\n",
    "#             edge_attr = self.lin_edge(mem)\n",
    "#             edge_attr = edge_attr.view(-1, self.heads, self.head_channels)\n",
    "#             alpha_edge = (edge_attr * self.att_edge).sum(dim=-1)\n",
    "#             shape = [1] * (alpha.ndim - 1) + [self.heads]\n",
    "#             shape[self.node_dim] = alpha_edge.size(0)\n",
    "#             alpha = alpha + alpha_edge.view(shape)\n",
    "\n",
    "#         alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "#         alpha = sparse_softmax(alpha,\n",
    "#                                index,\n",
    "#                                num_nodes=size_i,\n",
    "#                                ptr=ptr,\n",
    "#                                dim=self.node_dim)\n",
    "#         alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "#         return alpha, syn, mem\n",
    "\n",
    "#     def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n",
    "#         \"\"\"\"\"\"\n",
    "#         return alpha.unsqueeze(-1) * x_j\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "#                 f'{self.out_channels}, heads={self.heads})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = DiffConv(hidden_size, out_channels=hidden_size, k=2, activation='relu')\n",
    "emn_s = spatial(emb, batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.cat((emb, emn_s), dim=-1)\n",
    "stacked.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.layers.GSATConv import GSATConv\n",
    "res = GSATConv(in_channels=(1 * hidden_size) + hidden_size, out_channels=hidden_size, dim = 1, edge_dim=1)(stacked, batch.input.edge_index, batch.input.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter(torch.Tensor(1, 4, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.9\n",
    "rlif = snn.RLeaky(beta=beta, linear_features=hidden_size)\n",
    "spike, membrane_pot = rlif.init_rleaky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import surrogate\n",
    "spike_grad=surrogate.atan(alpha=2.0)\n",
    "thresh=1\n",
    "l = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=thresh, output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiplier(i):\n",
    "    return max((i * 2), 1)\n",
    "    # return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"size {emb.size(-1) * get_multiplier(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)\n",
    "# beta = torch.nn.Parameter(data=torch.tensor(0.9), requires_grad=True)\n",
    "synaptic = snn.Synaptic(\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True\n",
    "    )\n",
    "# syn, membrane_pot = synaptic.init_synaptic()\n",
    "\n",
    "synaptic2 = snn.Synaptic(\n",
    "    # alpha=torch.Tensor(emb.size(-1) * 2),\n",
    "    # beta=torch.Tensor(emb.size(-1) * 2),\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True\n",
    "    )\n",
    "# syn2, membrane_pot2 = synaptic2.init_synaptic()\n",
    "\n",
    "synaptic3 = snn.Synaptic(\n",
    "    # alpha=torch.Tensor(emb.size(-1) * 3),\n",
    "    # beta=torch.Tensor(emb.size(-1) * 3),\n",
    "    alpha=torch.Tensor(emb.size(-1)),\n",
    "    beta=torch.Tensor(emb.size(-1)),\n",
    "    learn_alpha=True,\n",
    "    learn_beta=True,\n",
    "    learn_threshold=True,\n",
    "    init_hidden=True,\n",
    "    output=True\n",
    "    )\n",
    "# syn3, membrane_pot3 = synaptic3.init_synaptic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synaptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=emb.size(-1), out_features=emb.size(-1))\n",
    "# linear2 = torch.nn.Linear(in_features=emb.size(-1) * 2, out_features=emb.size(-1) * 2)\n",
    "linear2 = torch.nn.Linear(in_features=emb.size(-1), out_features=emb.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.layers.SynapticChain import SynapticChain\n",
    "chain = SynapticChain(hidden_size=hidden_size, return_last=True)\n",
    "spike, mem_pot, syn_cur = chain(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(syn_cur).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes =[]\n",
    "mem_pots = []\n",
    "# flat = emb.flatten(start_dim=2)\n",
    "for timestep in range(t):\n",
    "    # spike, syn, membrane_pot = synaptic(emb[:, timestep,:, :], syn, membrane_pot)\n",
    "    spike = synaptic(emb[:, timestep,:, :])\n",
    "    l = linear(spike)\n",
    "    # spike2, syn2, membrane_pot2 = synaptic2(torch.cat((spike, emb[:, timestep,:, :]), dim=2), syn2, membrane_pot2)\n",
    "    # spike2, syn2, membrane_pot2 = synaptic2(torch.cat((l, emb[:, timestep,:, :]), dim=2), syn2, membrane_pot2)\n",
    "    spike2 = synaptic2(l)\n",
    "    l2 = linear2(spike2)\n",
    "    \n",
    "    # spike3, syn3, membrane_pot3 = synaptic3(torch.cat((l2, l), dim=2), syn3, membrane_pot3)\n",
    "    spike3, syn3, membrane_pot3 = synaptic3(l2)\n",
    "    \n",
    "    # spike, syn, membrane_pot = rsynaptic(flat[:, timestep, :], spike, syn, membrane_pot)\n",
    "    # spike, syn, membrane_pot = rsynaptic(emb[:, timestep, :, :], spike, syn, membrane_pot)\n",
    "    # spike, syn, membrane_pot = rsynaptic_conv(emb[:, timestep, :, :], spike, syn, membrane_pot)\n",
    "    spikes.append(spike3)\n",
    "    mem_pots.append(membrane_pot3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "855900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((spike, emb[:, 0,:, :]), dim=2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike.size(), syn.size(), membrane_pot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = DiffConv(in_channels=hidden_size,\n",
    "                                 out_channels=hidden_size,\n",
    "                                 k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_spikes = torch.stack(spikes, 1)\n",
    "post_space = space(stacked_spikes[:,-1,:,:], batch.edge_index, batch.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.Linear(32, input_size * horizon)\n",
    "post_decoder = decoder(post_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_decoder.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "rearrange = Rearrange('b n (t f) -> b t n f', t=horizon)\n",
    "post_rearange = rearrange(post_decoder)\n",
    "post_rearange.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rearange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(spikes, 1).size(), torch.stack(spikes, 1).reshape((b,t,n,-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike.reshape((b,n,-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=thresh)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb[:, 0, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk, mem = rlif(emb[:, 0, :, :], spike, membrane_pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk.size(), mem.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.TemporalSpikeGraphConvNet import TemporalSpikeGraphConvNet\n",
    "from models.TemporalSynapticGraphConvNet import TemporalSynapticGraphConvNet\n",
    "\n",
    "model = TemporalSynapticGraphConvNet(input_size=input_size,\n",
    "                               n_nodes=n_nodes,\n",
    "                               horizon=horizon,\n",
    "                               hidden_size=hidden_size * 5,\n",
    "                               output_type=\"membrane_potential\",\n",
    "                               number_of_blocks=3\n",
    "                               )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "batch.to(device)\n",
    "res = model(*batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
